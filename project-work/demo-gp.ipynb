{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from gplearn.genetic import SymbolicRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 2), (5000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = np.load('data/problem_4.npz')\n",
    "x = problem['x'].T\n",
    "y = problem['y']\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stefano\\OneDrive\\Desktop\\Computational intelligence\\CI2024_lab1\\venv\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    12.57          12.0339       28          3.17364          3.12112      1.29m\n",
      "   1     6.54          4.36951       21          3.02403          3.03547      1.20m\n",
      "   2     6.79      6.85289e+06       11          2.67816          2.45827      1.09m\n",
      "   3     8.22          4.70177       23          2.15173          2.31636     44.94s\n",
      "   4    10.64          4.09322       18          1.63629          1.64615     52.66s\n",
      "   5    16.10          3.55388       27          1.01976          1.03818     57.20s\n",
      "   6    23.21          16924.9       33         0.571169         0.541955     56.20s\n",
      "   7    29.68          2.57494       59         0.548706         0.526379      1.00m\n",
      "   8    31.25          2.28648       82         0.517565         0.530979     56.98s\n",
      "   9    33.33          2.04295       54         0.406219         0.421612     58.64s\n",
      "  10    34.51          1.93579       39         0.327273         0.316749     57.60s\n",
      "  11    34.45          1.95194       48         0.252188         0.238138     48.38s\n",
      "  12    34.20          1.89874       48         0.249674         0.260765     42.03s\n",
      "  13    34.76          1.73512       48         0.249291         0.264211     39.89s\n",
      "  14    32.58          1.79927       48         0.250931         0.249454     24.48s\n",
      "  15    31.71          1.87134       37         0.255128         0.264815     19.40s\n",
      "  16    31.49          1.70301       39         0.246342         0.248269     14.64s\n",
      "  17    32.34          2.04456       39         0.251966          0.26757     11.12s\n",
      "  18    31.85          1.74043       37         0.255378         0.262568      5.76s\n",
      "  19    31.19          2.06297       37         0.278527         0.280878      0.00s\n",
      "Best formula: add(add(add(add(cos(X1), tan(cos(X1))), add(sqrt(log(mul(0.048, X1))), add(add(cos(X1), cos(cos(X1))), cos(X1)))), cos(X1)), add(sqrt(add(tan(cos(X1)), cos(cos(X1)))), cos(X1)))\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the symbolic regressor\n",
    "est = SymbolicRegressor(\n",
    "    population_size=2000,\n",
    "    generations=20,\n",
    "    stopping_criteria=0.01,\n",
    "    function_set = ('add', 'sub', 'mul', 'div', 'sqrt', 'log', 'sin', 'cos', 'tan'),\n",
    "    p_crossover=0.7,\n",
    "    p_subtree_mutation=0.1,\n",
    "    p_hoist_mutation=0.05,\n",
    "    p_point_mutation=0.1,\n",
    "    max_samples=0.9,\n",
    "    verbose=1,\n",
    "    parsimony_coefficient=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "est.fit(x_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = est.predict(x_valid)\n",
    "\n",
    "# Print the resulting formula\n",
    "print(\"Best formula:\", est._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.12296306427653768\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and visualize\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
